{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Atividade 1 - Parte A – Reconhecimento de Imagens e Visão Computacional</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aluno: Aderson Lucas Guimarães Mendonça Medeiros<br>\n",
    "Matrícula: 1831143043"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercício 1</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Crie uma função (em Python)  que seja capaz de reduzir e/ou aumentar a resolução espacial de uma imagem por um fator n, que é um número real positivo (n>1 para um aumento da resolução espacial e n< 1 para uma redução da resolução espacial).  Tal função deve possuir como parâmetros de entrada, o nome do arquivo da imagem para leitua no disco e o fator n. Para aumento da resolução utilize a técnica do vizinho-mais-próximo vista em sala de aula. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports packages\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcao para redimensionar a imagem\n",
    "def rescale_image(image_ri, proportion_ri, interpolation=None):\n",
    "    #   avalia se o parametro que foi passado para a imagem foi um caminho para o\n",
    "    #    arquivo ou uma imagem em forma de numpy array\n",
    "    image_result = np.array([])\n",
    "    if type(image_result) == str:\n",
    "        image_result = cv2.imread(image_ri)\n",
    "    elif type(image_result) == np.ndarray:\n",
    "        image_result = np.copy(image_ri)\n",
    "    # Se o parametro de proporção for maior que 1 será feita interpolação dependendo\n",
    "    # do parametro interpolação\n",
    "    if proportion_ri >= 1:\n",
    "        if interpolation == 'vizinho':\n",
    "            image_result = rescale_image_neighbor(image_result, proportion_ri)\n",
    "        elif interpolation == 'bilinear':\n",
    "            image_result = rescale_image_bilinear(image_result, proportion_ri)\n",
    "    \n",
    "    # Esse caso se refere à redução das proporções e nesse caso trataremos de\n",
    "    #  eliminar pixels\n",
    "    elif proportion_ri > 0:\n",
    "        proportion_division = 1/proportion_ri\n",
    "        row, col = image_result.shape[:2]\n",
    "        row_scale = [r for r in range(row) if not (int(r%proportion_division) == 0)]\n",
    "        col_scale = [c for c in range(col) if not (int(c%proportion_division) == 0)]\n",
    "        image_result = np.delete(image_result, row_scale, axis=0)\n",
    "        image_result = np.delete(image_result, col_scale, axis=1)\n",
    "    return image_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcao para aumentar a proporção da imagem utilizando vizinho mais próximo\n",
    "def rescale_image_neighbor(image, proportion):\n",
    "    image_rescale = np.copy(image)\n",
    "    # get the row, column and channel lengths\n",
    "    row, col = image.shape[:2]\n",
    "    new_row, new_col = \\\n",
    "        [np.floor(entry*proportion) for entry in image_rescale.shape[:2]]\n",
    "    row_index = 1\n",
    "    resto_sum = 0\n",
    "    while row_index < new_row:\n",
    "        qtd_row_insert = proportion - 1\n",
    "        while qtd_row_insert >= 0:\n",
    "            if qtd_row_insert >= 1:\n",
    "                image_rescale = np.insert(image_rescale,\n",
    "                                            row_index, \n",
    "                                            image_rescale[row_index-1,:], \n",
    "                                            axis=0)\n",
    "                row_index += 1\n",
    "                qtd_row_insert -= 1\n",
    "            elif qtd_row_insert >= 0:\n",
    "                resto_sum += qtd_row_insert\n",
    "                row_index += 1\n",
    "                qtd_row_insert -= 1\n",
    "            if resto_sum >= 1:\n",
    "                image_rescale = np.insert(image_rescale, row_index, 0, axis=0)\n",
    "                row_index += 1\n",
    "                resto_sum -= 1\n",
    "            row, _ = image_rescale.shape[:2]\n",
    "\n",
    "    col_index = 1\n",
    "    resto_sum = 0\n",
    "    while col_index < new_col:\n",
    "        qtd_col_insert = proportion - 1\n",
    "        while qtd_col_insert >= 0:\n",
    "            if qtd_col_insert >= 1:\n",
    "                image_rescale = np.insert(image_rescale,\n",
    "                                          col_index,\n",
    "                                          image_rescale[:,col_index-1],\n",
    "                                          axis=1)\n",
    "                col_index += 1\n",
    "                qtd_col_insert -= 1\n",
    "            elif qtd_col_insert >= 0:\n",
    "                resto_sum += qtd_col_insert\n",
    "                col_index += 1\n",
    "                qtd_col_insert -= 1\n",
    "            if resto_sum >= 1:\n",
    "                image_rescale = np.insert(image_rescale,\n",
    "                                          col_index,\n",
    "                                          image_rescale[:,col_index-1],\n",
    "                                          axis=1)\n",
    "                col_index += 1\n",
    "                resto_sum -= 1\n",
    "            _, col = image_rescale.shape[:2]\n",
    "            \n",
    "    return image_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_bilinear_por_pixel(imArr, posX, posY):\n",
    "    pixel_resultado = 0\n",
    " \n",
    "    #Get integer and fractional parts of numbers\n",
    "    modXi = int(posX)\n",
    "    modYi = int(posY)\n",
    "    modXf = posX - modXi\n",
    "    modYf = posY - modYi\n",
    "    modXiPlusOneLim = min(modXi+1,imArr.shape[1]-1)\n",
    "    modYiPlusOneLim = min(modYi+1,imArr.shape[0]-1)\n",
    " \n",
    "    #Get pixels in four corners\n",
    "    bl = imArr[modYi, modXi]\n",
    "    br = imArr[modYi, modXiPlusOneLim]\n",
    "    tl = imArr[modYiPlusOneLim, modXi]\n",
    "    tr = imArr[modYiPlusOneLim, modXiPlusOneLim]\n",
    "\n",
    "    #Calculate interpolation\n",
    "    b = modXf * br + (1. - modXf) * bl\n",
    "    t = modXf * tr + (1. - modXf) * tl\n",
    "    pxf = modYf * t + (1. - modYf) * b\n",
    "    pixel_resultado = int(pxf+0.5)\n",
    " \n",
    "    return pixel_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_image_bilinear(image_rib, proportion_rib):\n",
    "    enlargedShape = \\\n",
    "        list(map(int, [image_rib.shape[0]*proportion_rib, \n",
    "                       image_rib.shape[1]*proportion_rib]))\n",
    "    if np.size(image_rib[0,0]) > 1:\n",
    "        enlargedShape.append(image_rib.shape[2])\n",
    "    enlargedImg = np.empty(enlargedShape, dtype=np.uint8)\n",
    "    rowScale = float(image_rib.shape[0]) / float(enlargedImg.shape[0])\n",
    "    colScale = float(image_rib.shape[1]) / float(enlargedImg.shape[1])\n",
    " \n",
    "    for r in range(enlargedImg.shape[0]):\n",
    "        for c in range(enlargedImg.shape[1]):\n",
    "            orir = r * rowScale #Find position in original image\n",
    "            oric = c * colScale\n",
    "            if np.size(image_rib[0,0]) == 1:\n",
    "                enlargedImg[r, c] = \\\n",
    "                    processar_bilinear_por_pixel(image_rib, oric, orir)\n",
    "            elif np.size(image_rib[0,0]) > 1:\n",
    "                enlargedImg[r, c] = \\\n",
    "                    [processar_bilinear_por_pixel(image_rib[:,:,chn], oric, orir)\n",
    "                     for chn in range(enlargedImg.shape[2])]\n",
    "    \n",
    "    return enlargedImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding image to run the algorithm\n",
    "def pad_image(image_pi, type_pad, rgb=False):\n",
    "    # If image is rgb make a frame of pixel taken from the edge of the image\n",
    "    # for each color\n",
    "    if rgb:\n",
    "        im_padded = [np.pad(image_pi[:,:,i], 1, type_pad)\n",
    "                     for i in range(image_pi.shape[-1])]\n",
    "        im_padded = [np.expand_dims(image_p, axis=2) for image_p in im_padded]\n",
    "        return np.concatenate(im_padded, axis=2)\n",
    "    # If image is rgb make a frame of pixel taken from the edge of the image\n",
    "    else:\n",
    "        return np.copy(np.pad(image_pi, 1, type_pad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar imagens\n",
    "def show_subplots_image(image_array, nrow, ncol,fig_size_array, \n",
    "                        title_array, cmap=None):\n",
    "    fig, axes = plt.subplots(nrow, ncol, figsize=fig_size_array)\n",
    "    for ax, image, title in zip(axes.flatten(), image_array, title_array):\n",
    "        ax.axis('off')\n",
    "        ax.set_title(title)\n",
    "        fig.tight_layout()\n",
    "        ax.imshow(image, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redifine_image_reduce_to_show_scale(image_rirtds, image_reference):\n",
    "    image_redefine = np.copy(image_rirtds)\n",
    "    image_result = list()\n",
    "    for image_idx, image_resize in enumerate(image_redefine):\n",
    "        image_ones = np.ones(image_reference.shape)\n",
    "        for i in range(image_ones.shape[0]):\n",
    "            for j in range(image_ones.shape[1]):\n",
    "                if i < image_resize.shape[0] and j < image_resize.shape[1]:\n",
    "                    image_ones[i,j] = image_resize[i,j]\n",
    "                else:\n",
    "                    image_ones[i,j] = image_reference[i,j]\n",
    "        image_result.append(image_ones)\n",
    "    return np.array(image_result).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Utilize o sua função do item anterior para gerar imagens com resolução espacial reduzida por fatores de 2, 4, 8 e 16. Em seguida, utilize o seu programa novamente para aumentar estas imagens de volta ao seu tamanho original. Há diferenças de qualidade entre estas imagens? Comente. (Obs.: Plote os resultados para que possam se visualizados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar imagem, converter para RGB e normaliza-la\n",
    "image_exercicio_1 = cv2.imread('../imagens/image.jpg')\n",
    "image_exercicio_1 = cv2.cvtColor(image_exercicio_1, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_list = [1/2, 1/4, 1/8, 1/16]\n",
    "title_array = ['1/2 da Imagem', '1/4 da Imagem', '1/8 da Imagem', '1/16 da Imagem']\n",
    "imagem_reduce_array = [rescale_image(image_exercicio_1, proportion_ri=proportion)\n",
    "                       for proportion in proportion_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show images\n",
    "image_to_plot_reduce = redifine_image_reduce_to_show_scale(imagem_reduce_array,\n",
    "                                                           image_exercicio_1)\n",
    "IMAGE_SIZE=[20,20]\n",
    "show_subplots_image(image_to_plot_reduce, 2, 2, IMAGE_SIZE,\n",
    "                    title_array=title_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_expand_list = [2, 4, 8, 16]\n",
    "expand_proportion = zip(imagem_reduce_array, proportion_expand_list)\n",
    "imagem_vizinho = \\\n",
    "    [rescale_image(im_expand, proportion_ri=proportion, interpolation='vizinho')\n",
    "     for im_expand, proportion in expand_proportion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show images\n",
    "title_expand = ['2x Aumentada', '4x Aumentada', '8x Aumentada', '16x Aumentada']\n",
    "show_subplots_image(imagem_vizinho, 2, 2, IMAGE_SIZE, title_expand, 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Resposta:</b><br><br>\n",
    "É notável a diferença de qualidade entre a imagem original e sua cópia restaurada. O processo de reduzir a imagem obriga a perda dos pixels reais da imagem. Ao restaurar utilizando interpolação o algoritmo tenta inferir qual seriam os pixels que compunham as lacunas entre os pixeis originais ainda existentes na imagem reduzida. Assim, é muito difícil obter uma imagem identica à original através desse processo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Modifique a função desenvolvida em (a), de forma que seja utilizada a técnica de interpolação bilinear e refaça o que se pede no item (b) novamente. (Obs.: Plote os resultados para que possam se visualizados). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_proportion_bilinear = zip(imagem_reduce_array, proportion_expand_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_bilinear = \\\n",
    "    [rescale_image(im_expand, proportion_ri=proportion, interpolation='bilinear')\n",
    "     for im_expand, proportion in expand_proportion_bilinear]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show images\n",
    "show_subplots_image(imagem_bilinear, 2, 2, IMAGE_SIZE, title_expand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Resposta:</b><br><br>\n",
    "Novamente pode-se observar que a imagem restaurada não possui a qualidade da imagem original pelo mesmo processo de perda e inferência dos pixeis no processo. No entanto, o algoritmo que utiliza a interpolação bilinear consegue obter uma suavização melhor ao inferir as lacunas entre os pixels originais. A qualidade nesse caso é superior ao método de restauração utilizando o algoritmo de vizinho mais próximo obtido no item anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercício 2</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Escreva uma função que realize a filtragem espacial de uma imagem. Essa função terá 2 parâmetros de entrada:  a imagem a ser transformada e o filtro a ser utilizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtragem_espacial(image_fe:np.array, filtro_fe:np.array):\n",
    "    filtered_image = np.copy(image_fe)\n",
    "    if np.size(image_fe[0,0]) == 1:\n",
    "        filtered_image = filtragem_channel(image_fe, filtro_fe, rgb=False)\n",
    "    else:\n",
    "        for chn in range(np.size(image_fe[0,0])):\n",
    "            filtered_image[:,:,chn] = filtragem_channel(image_fe[:,:,chn], filtro_fe)\n",
    "    \n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realiza a filtragem espacial aplicando o filtro na imagem\n",
    "def filtragem_channel(image_fc:np.array, filtro_fc:np.array, rgb=True):\n",
    "    padding_size = (int(filtro_fc.shape[0]/2), int(filtro_fc.shape[1]/2))\n",
    "    imagem_transicao = np.copy(np.pad(image_fc, \n",
    "                                      padding_size, \n",
    "                                      'constant', \n",
    "                                      constant_values=(0)))\n",
    "    imagem_filtrada = np.zeros(image_fc.shape)\n",
    "    \n",
    "    for i in range(padding_size[0], imagem_transicao.shape[0] - padding_size[0]):\n",
    "        for j in range(padding_size[1], imagem_transicao.shape[1] - padding_size[1]):\n",
    "            if i - 1 < image_fc.shape[0] and j - 1 < image_fc.shape[1]:\n",
    "                imagem_filtrada[i - 1, j - 1] = int(np.sum(\n",
    "                    (imagem_transicao[i-padding_size[0]:i+padding_size[0]+1,\n",
    "                     j-padding_size[1]:j+padding_size[1]+1].flatten())*\n",
    "                    (filtro_fc.flatten())))\n",
    "\n",
    "    imagem_final = cv2.normalize(imagem_filtrada,None,alpha=np.min(imagem_filtrada), \n",
    "                                beta=np.max(imagem_filtrada), norm_type=cv2.NORM_MINMAX)\n",
    "                \n",
    "    return imagem_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Aplique os filtros abaixo na imagem da Lena (que foi enviada com o trabalho). Compare os resultados obtidos para cada um dos filtros. Com base nestes resultados, qual o tipo de filtro (passa-alta, passa\n",
    "baixa, passa-faixa, etc.)  que está sendo utilizado em cada caso e qual o efeito de cada filtro na imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega a imagem da lenna\n",
    "image_exercicio_2 = cv2.imread('../imagens/lenna.png', cv2.IMREAD_GRAYSCALE)\n",
    "IMAGE_SIZE = [12,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega os filtros para o exercício\n",
    "filter_list_exercicio_2b = [\n",
    "                            np.array(np.dot((1/9),[[1,1,1],[1,1,1],[1,1,1]])),\n",
    "                            np.array(np.dot((1/16),[[1,2,1],[2,4,2],[1,2,1]])),\n",
    "                            np.array([[0,-1,0],[-1,5,-1],[0,-1,0]]),\n",
    "                            np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]]),\n",
    "                            np.array([[1,2,1],[0,0,0],[-1,-2,-1]])\n",
    "                        ]\n",
    "\n",
    "# Título dos gráficos\n",
    "filter_list_exercicio_2b_titles = ['Imagem Original',\n",
    "                                   'Filtro de Média 1/9',\n",
    "                                   'Filtro de Média 1/16',\n",
    "                                   'Laplaciano com 5 no centro',\n",
    "                                   'Laplaciano com 8 no centro',\n",
    "                                   'Último filtro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o filtro na imagem usando os filtros acima e Agrega a imagem original\n",
    "image_filtered_list = \\\n",
    "    np.array([filtragem_espacial(image_exercicio_2, filter_2b) \n",
    "              for filter_2b in filter_list_exercicio_2b])\n",
    "image_filtered_list = np.concatenate(([image_exercicio_2], image_filtered_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exibe as imagens finais\n",
    "show_subplots_image(image_filtered_list, \n",
    "                    3, 2, \n",
    "                    IMAGE_SIZE, \n",
    "                    filter_list_exercicio_2b_titles, 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) O filtro 1 possui tamanho 3x3. O que aconteceria se aumentássemos o tamanho do filtro para 11x11, 17x17 ou 35x35? De que forma o tamanho do filtro afeta a imagem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os filtros de média multiplicado por 1/9 com vários tamanhos de matrix\n",
    "filter_list_exercicio_2c = np.array([np.dot((1/9), np.ones((3,3))),\n",
    "                            np.dot((1/9), np.ones((11,11))),\n",
    "                            np.dot((1/9), np.ones((17,17))),\n",
    "                            np.dot((1/9), np.ones((35,35)))])\n",
    "\n",
    "# Carregas os títulos dos gráficos\n",
    "ilter_list_exercicio_2c_titles = ['Filtro 3 x 3', \n",
    "                                  'Filtro 11 x 11', \n",
    "                                  'Filtro 17 x 17', \n",
    "                                  'Filtro 35 x 35']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o filtro na imagem usando os filtros acima\n",
    "imagem_filtrada_list_exercicio_2c = \\\n",
    "    [filtragem_espacial(image_exercicio_2, filtro_2c) \n",
    "     for filtro_2c in filter_list_exercicio_2c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show images\n",
    "show_subplots_image(imagem_filtrada_list_exercicio_2c, \n",
    "                    2, 2,\n",
    "                    IMAGE_SIZE,\n",
    "                    ilter_list_exercicio_2c_titles,\n",
    "                    'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercício 3</b> - Neste exercício, vamos examinar a resposta em frequência dos seguintes filtros espaciais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera o modulo de uma lista de imagens\n",
    "def gerar_modulo(image_filter_gm, s_gm:tuple=None, transform_gm=None):\n",
    "    fft_image = np.fft.fft2(image_filter_gm, s=s_gm)   \n",
    "    fft_filters_shift = np.fft.fftshift(fft_image)\n",
    "    if transform_gm == None:\n",
    "        return np.abs(fft_filters_shift)\n",
    "    else:\n",
    "        return np.abs(transform_gm(fft_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera modulo de filtro e aplica a imagem transformada para obter o modulo \n",
    "# da transformada inversa\n",
    "def gerar_modulo_imagem_filtrada(image_mod_filt_gmif, filter_list_gmif):\n",
    "    # obter o modulo de uma lista de filtros\n",
    "    fft_filters_shift_abs = \\\n",
    "        [gerar_modulo(filter_gmif, s_gm=image_mod_filt_gmif.shape) \n",
    "         for filter_gmif in filter_list_gmif]\n",
    "    fft_image = np.fft.fft2(image_mod_filt_gmif)\n",
    "    fft_image_shift = np.fft.fftshift(fft_image)\n",
    "    fft_image_filtered_list = [fft_image_shift*filter_gmif \n",
    "                               for filter_gmif in fft_filters_shift_abs]\n",
    "    ifft_shift_image_filtered_list = [np.fft.ifftshift(fft_image_filt) \n",
    "                                      for fft_image_filt in fft_image_filtered_list]\n",
    "    img_back_list = [np.fft.ifft2(image_ifft_filt) \n",
    "                     for image_ifft_filt in ifft_shift_image_filtered_list]\n",
    "    return [abs(image_complex) for image_complex in img_back_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Converta os filtros h1 e h2 para  o domínio da frequência. Visualize o módulo de cada filtro. Obs: Para visualizar melhor a resposta do filtro no domínio da frequência desloque a freq. (0,0) para o centro da imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a imagem que será utilizada no exercício\n",
    "image_exercicio_3 = cv2.imread('../imagens/lenna.png', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar of filtros\n",
    "filters_list = list([np.dot(1/25,np.ones((5,5))), \n",
    "                     np.array([[1,2,1], [0,0,0],[-1,-2,-1]])])\n",
    "\n",
    "# tamanho das imagens a serem exibidas\n",
    "IMAGE_SIZE = [8,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerar o módulo no domínio de frequência dos filtros\n",
    "title_array = ['Domínio de Frequência da Imagem', 'Domínio de Frequência do Filtro']\n",
    "row_size, col_size = image_exercicio_3.shape\n",
    "fft_filters_shift_abs = [gerar_modulo(filter_a, \n",
    "                         s_gm=(row_size, col_size)) \n",
    "                         for filter_a in filters_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exibir as imagens que representam os filtos no domínio de frequência\n",
    "show_subplots_image(fft_filters_shift_abs, 1, 2, IMAGE_SIZE, title_array, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Filtre, no domínio da frequência, três imagens (diferentes) com cada um dos dois filtro. Em seguida, tire a transformada inversa. O resultado da filtragem espacial é  o mesmo de filtragem no domínio da frequência? Justifique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar as imagens\n",
    "images_path_pokemon = ['../imagens/th35SNIA8N.jpg', \n",
    "                       '../imagens/thBRXJU7EY.jpg',\n",
    "                       '../imagens/1200px-Scorbunny.png']\n",
    "images_list_pokemon = [cv2.imread(pokemon, cv2.IMREAD_GRAYSCALE) \n",
    "                       for pokemon in images_path_pokemon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerar o módulo no domínio de frequência das imagens\n",
    "fft_filters_shift_abs = \\\n",
    "    [gerar_modulo(image_pokemon, transform_gm=np.log) \n",
    "     for image_pokemon in images_list_pokemon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exibir as imagens no domínio de frequência\n",
    "title_array = ['Domínio de Frequência do Pokemon 1', \n",
    "               'Domínio de Frequência do Pokemon 2',\n",
    "               'Domínio de Frequência do Pokemon 3']\n",
    "show_subplots_image(fft_filters_shift_abs, 3, 1, IMAGE_SIZE, title_array, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicar a transformada inversa e obter o modulo da imagem após filtragem \n",
    "# no domínio de frequência'\n",
    "img_back_abs_list = [gerar_modulo_imagem_filtrada(image_pokemon, filters_list) \n",
    "                     for image_pokemon in images_list_pokemon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show images\n",
    "for index, subplot_image in enumerate(img_back_abs_list):\n",
    "    title_array = ['Pokemon {} com filtro de média \\n no domínio de frequência'\n",
    "                       .format(index + 1),\n",
    "                   'Pokemon {} com filtro Sobel \\n no domínio de frequência'\n",
    "                       .format(index + 1)]\n",
    "    show_subplots_image(subplot_image, 1, 2, IMAGE_SIZE, title_array, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicar os filtros às imagens\n",
    "image_filtragem_espacial = [cv2.filter2D(image_pokemon, -1, filter_pokemon) \n",
    "                                for image_pokemon in images_list_pokemon \n",
    "                                for filter_pokemon in filters_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exibir as imagens filtradas\n",
    "image_filtragem_espacial = np.array(image_filtragem_espacial).reshape(-1,2)\n",
    "for index, subplot_image in enumerate(image_filtragem_espacial):\n",
    "    title_array = ['Pokemon {} com filtro de média'.format(index + 1), \n",
    "                   'Pokemon {} com filtro Sobel'.format(index + 1)]\n",
    "    show_subplots_image(subplot_image, 1, 2, IMAGE_SIZE, title_array, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como observado a filtragem no domínio da frequência apresenta o mesmo resultado de uma filtragem sem aplicação de transformações nas imagens. Isso ocorre porque a transformada de Fourier decompõe as frequências em somas de frequências que totalizam a frequência original e é uma transformação reversível sem perda de informação. Portanto, ao se realizar a filtragem no domínio de frequência propaga a filtragem mantendo a estrutura necessária para uma completa reversibilidade a partir da transformação inversa de Fourier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercício 4</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Tire a transformada das imagens noiseball.png e footBallOrig.png (enviadas juntas com a atividade). Visualize o módulo destas transformadas. Há alguma diferença?  É possível recuperar a imagem noiseball.png  e eliminar o ruído? Justifique sua resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar as imagens\n",
    "images_list_ball_path = ['../imagens/footBallOrig.png', \n",
    "                         '../imagens/noiseball.png']\n",
    "images_list_ball = [cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) \n",
    "                    for image_path in images_list_ball_path]\n",
    "for img_inedx, image in enumerate(images_list_ball):\n",
    "    images_list_ball[img_inedx] = \\\n",
    "        cv2.normalize(images_list_ball[img_inedx],\n",
    "                      None,alpha=0,beta=1, \n",
    "                      norm_type=cv2.NORM_MINMAX,\n",
    "                      dtype=cv2.CV_32F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_filters_shift_abs_ball = [gerar_modulo(images_ball, transform_gm=np.log)\n",
    "                              for images_ball in images_list_ball]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra as images no domínio de frequência\n",
    "title_array = ['Dominío de frequência da Bola sem ruído',\n",
    "               'Dominío de frequência da Bola com ruído']\n",
    "show_subplots_image(fft_filters_shift_abs_ball, \n",
    "                    2, 1, \n",
    "                    [20,20], \n",
    "                    title_array, \n",
    "                    cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " b) Tire a transformada inversa da imagem filtrada e visualize o resultado. Comente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os filtros\n",
    "filters_list_ball = \\\n",
    "    list([np.array(np.dot(1/25,[[2,4,4,4,2], \n",
    "                                [2,4,4,4,2], \n",
    "                                [2,4,4,4,2], \n",
    "                                [2,4,4,4,2], \n",
    "                                [2,4,4,4,2]]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o filtro às imagens no domínio de frequência e proceder \n",
    "# com a transformada inversa\n",
    "img_back_abs_list = \\\n",
    "    gerar_modulo_imagem_filtrada(images_list_ball[1], filters_list_ball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar a imagem filtrada\n",
    "final_image_filtered = [images_list_ball[1], \n",
    "                        img_back_abs_list[0]]\n",
    "title_array = ['Imagem da Bola com ruído',\n",
    "               'Imagem da Bola filtrada utilizando filtro de média']\n",
    "show_subplots_image(final_image_filtered, 2, 1, [20,20], title_array, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível verificar que apesar de ter perdido um pouco de nitidez o ruído foi praticamente todo eliminado. Nesse caso foi utilizado um filtro de média, pois o objetivo era usar um filtro de passa-baixo. Observando a imagem com ruído no domínio de frequência pode-se perceber que existem picos de frequência e nesse caso o filtro selecionado apresenta um resultado positivo como obtido no resultado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
